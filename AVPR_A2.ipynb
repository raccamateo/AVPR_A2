{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.optim import lr_scheduler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Stanford40Dataset(Dataset):\n",
    "    def __init__(self, img_dir, split_file, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        with open(split_file, 'r') as file:\n",
    "            self.img_list = file.readlines()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx].rstrip('\\n')\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure image is RGB\n",
    "        label = img_name.split('_')[0]  # Extract action name from file name\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = Compose([\n",
    "    Resize((256, 256)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Paths to the directories and split files\n",
    "img_dir = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/JPEGImages'\n",
    "train_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/train.txt'\n",
    "test_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/test.txt'\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = Stanford40Dataset(img_dir=img_dir, split_file=train_split_file, transform=transform)\n",
    "test_dataset = Stanford40Dataset(img_dir=img_dir, split_file=test_split_file, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc2695660f5f465b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256]) ('pouring', 'playing', 'rowing', 'watching', 'pushing', 'blowing', 'phoning', 'looking', 'playing', 'walking', 'smoking', 'playing', 'jumping', 'waving', 'pouring', 'using', 'pushing', 'playing', 'phoning', 'running', 'jumping', 'using', 'writing', 'writing', 'pushing', 'applauding', 'washing', 'playing', 'playing', 'throwing', 'fixing', 'riding')\n"
     ]
    }
   ],
   "source": [
    "# Example to get one batch of data\n",
    "for images, labels in train_loader:\n",
    "    # Here images is a batch of images and labels is a batch of corresponding labels\n",
    "    print(images.shape, labels)\n",
    "    break  # Remove this break to iterate over the whole dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea8cf0df5bf15f1"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy: 11.171366594360087%\n",
      "Epoch 2: Validation Accuracy: 11.478669558929862%\n",
      "Epoch 3: Validation Accuracy: 12.79826464208243%\n",
      "Epoch 4: Validation Accuracy: 13.322487346348518%\n",
      "Epoch 5: Validation Accuracy: 13.376717281272596%\n",
      "Test Accuracy: 13.250180766449747%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Dataset class for Stanford 40\n",
    "class Stanford40Dataset(Dataset):\n",
    "    def __init__(self, img_dir, split_file, transform=None, label_dict=None):\n",
    "        self.img_dir = img_dir\n",
    "        with open(split_file, 'r') as file:\n",
    "            self.img_list = file.readlines()\n",
    "        self.transform = transform\n",
    "        self.label_dict = label_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx].rstrip('\\n')\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.label_dict[img_name.split('_')[0]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "# Enhanced Transform with Augmentations\n",
    "transform = Compose([\n",
    "    Resize((256, 256)), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Paths and dataset loaders\n",
    "img_dir = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/JPEGImages'\n",
    "train_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/train.txt'\n",
    "test_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/test.txt'\n",
    "unique_labels = sorted(set([line.split('_')[0] for line in open(train_split_file, 'r')]))\n",
    "label_dict = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "train_dataset = Stanford40Dataset(img_dir, train_split_file, transform=transform, label_dict=label_dict)\n",
    "test_dataset = Stanford40Dataset(img_dir, test_split_file, transform=transform, label_dict=label_dict)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=40, activation='tanh'):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        # Define layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(128, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Activation function selection\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activation(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.activation(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.activation(self.bn3(self.conv3(x))))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Validation function\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model and move it to the device\n",
    "model = EnhancedCNN(num_classes=40, activation='tanh').to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer with the learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.05)\n",
    "\n",
    "# Specify the number of epochs \n",
    "num_epochs = 5  \n",
    "\n",
    "# Initialize the best validation accuracy variable\n",
    "best_acc = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over the training set\n",
    "    for images, labels in train_loader:\n",
    "        # Transfer images and labels to your device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Adjust the learning rate based on the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Validation step after each epoch\n",
    "    val_acc = validate(model, test_loader)\n",
    "    print(f'Epoch {epoch+1}: Validation Accuracy: {val_acc}%')\n",
    "    \n",
    "    # Check if the validation accuracy is the best and save the model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Test function\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Test the model after training\n",
    "test_accuracy = test_model(model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy}%')\n",
    "\n",
    "# Save test results to a file\n",
    "with open('test_accuracy.txt', 'w') as file:\n",
    "    file.write(f'Test Accuracy: {test_accuracy}%\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T21:54:54.308774Z",
     "start_time": "2024-01-09T21:34:42.363838Z"
    }
   },
   "id": "48f15ce094b0e69c"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 2.2729, Validation Loss: 1.4564, Validation Accuracy: 62.04%\n",
      "Epoch 2/10, Training Loss: 1.1292, Validation Loss: 1.1175, Validation Accuracy: 69.49%\n",
      "Epoch 3/10, Training Loss: 0.7161, Validation Loss: 0.9579, Validation Accuracy: 74.02%\n",
      "Epoch 4/10, Training Loss: 0.4511, Validation Loss: 0.9354, Validation Accuracy: 73.93%\n",
      "Epoch 5/10, Training Loss: 0.2859, Validation Loss: 0.8778, Validation Accuracy: 75.23%\n",
      "Epoch 6/10, Training Loss: 0.1784, Validation Loss: 0.8959, Validation Accuracy: 74.48%\n",
      "Epoch 7/10, Training Loss: 0.1172, Validation Loss: 0.8805, Validation Accuracy: 74.96%\n",
      "Epoch 8/10, Training Loss: 0.0799, Validation Loss: 0.8438, Validation Accuracy: 75.94%\n",
      "Epoch 9/10, Training Loss: 0.0597, Validation Loss: 0.8669, Validation Accuracy: 75.23%\n",
      "Epoch 10/10, Training Loss: 0.0422, Validation Loss: 0.8206, Validation Accuracy: 76.48%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "# Dataset class for Stanford 40\n",
    "class Stanford40Dataset(Dataset):\n",
    "    def __init__(self, img_dir, split_file, transform=None, label_dict=None):\n",
    "        self.img_dir = img_dir\n",
    "        with open(split_file, 'r') as file:\n",
    "            self.img_list = file.readlines()\n",
    "        self.transform = transform\n",
    "        self.label_dict = label_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx].rstrip('\\n')\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.label_dict[img_name.split('_')[0]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "# Enhanced Transform with Augmentations\n",
    "transform = Compose([\n",
    "    Resize((256, 256)), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Paths and dataset loaders\n",
    "img_dir = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/JPEGImages'\n",
    "train_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/train.txt'\n",
    "test_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/test.txt'\n",
    "unique_labels = sorted(set([line.split('_')[0] for line in open(train_split_file, 'r')]))\n",
    "label_dict = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "\n",
    "train_dataset = Stanford40Dataset(img_dir, train_split_file, transform=transform, label_dict=label_dict)\n",
    "test_dataset = Stanford40Dataset(img_dir, test_split_file, transform=transform, label_dict=label_dict)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "resnet_model = models.resnet18(pretrained=True)\n",
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, 40)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(resnet_model.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return val_loss / len(val_loader), 100 * correct / total\n",
    "\n",
    "\n",
    "best_model_wts = copy.deepcopy(resnet_model.state_dict())\n",
    "best_acc = 0.0\n",
    "early_stopping_patience = 5\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "num_epochs = 10  # Set  number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    resnet_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    val_loss, val_acc = validate(resnet_model, test_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%')\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(resnet_model.state_dict())\n",
    "        torch.save(resnet_model.state_dict(), 'resnet_best_model.pth')\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "        if no_improvement_epochs >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "resnet_model.load_state_dict(best_model_wts)\n",
    "\n",
    "\n",
    "# Test function\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "test_accuracy = test_model(resnet_model, test_loader)\n",
    "with open('resnet_test_results.txt', 'w') as file:\n",
    "    file.write(f'Test Accuracy: {test_accuracy}%\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:24:46.941197Z",
     "start_time": "2024-01-09T23:06:00.815857Z"
    }
   },
   "id": "80c2bea3b4d468f0"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to read accuracy from text file\n",
    "def read_accuracy(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        accuracy = file.readline().strip()\n",
    "        try:\n",
    "            return float(accuracy.split(': ')[1].replace('%', ''))\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "# Paths to your accuracy text files\n",
    "relu_accuracy_file = '/Users/mwr/Downloads/AVPR assignment 2/relu_test_accuracy.txt'\n",
    "sigmoid_accuracy_file = '/Users/mwr/Downloads/AVPR assignment 2/sigmoid_test_accuracy.txt'\n",
    "tanh_accuracy_file = '/Users/mwr/Downloads/AVPR assignment 2/tanh_test_accuracy.txt'\n",
    "resnet_accuracy_file = '/Users/mwr/Downloads/AVPR assignment 2/resnet_test_accuracy.txt'\n",
    "\n",
    "# Reading accuracies\n",
    "relu_accuracy = read_accuracy(relu_accuracy_file)\n",
    "sigmoid_accuracy = read_accuracy(sigmoid_accuracy_file)\n",
    "tanh_accuracy = read_accuracy(tanh_accuracy_file)\n",
    "resnet_accuracy = read_accuracy(resnet_accuracy_file)\n",
    "\n",
    "# Plotting accuracies\n",
    "models = ['ReLU', 'Sigmoid', 'Tanh', 'ResNet']\n",
    "accuracies = [relu_accuracy, sigmoid_accuracy, tanh_accuracy, resnet_accuracy]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, accuracies, color=['blue', 'green', 'red', 'purple'])\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.ylim([0, 100])  # Assuming accuracy percentages\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i, v + 0.5, f\"{v}%\", ha='center', va='bottom')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:03:29.187980Z",
     "start_time": "2024-01-10T10:03:29.087815Z"
    }
   },
   "id": "fbc26d95731db87d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ba6b520f68b177d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
