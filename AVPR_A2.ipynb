{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.optim import lr_scheduler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Stanford40Dataset(Dataset):\n",
    "    def __init__(self, img_dir, split_file, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        with open(split_file, 'r') as file:\n",
    "            self.img_list = file.readlines()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx].rstrip('\\n')\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure image is RGB\n",
    "        label = img_name.split('_')[0]  # Extract action name from file name\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = Compose([\n",
    "    Resize((256, 256)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Paths to the directories and split files\n",
    "img_dir = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/JPEGImages'\n",
    "train_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/train.txt'\n",
    "test_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/test.txt'\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = Stanford40Dataset(img_dir=img_dir, split_file=train_split_file, transform=transform)\n",
    "test_dataset = Stanford40Dataset(img_dir=img_dir, split_file=test_split_file, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc2695660f5f465b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256]) ('pouring', 'playing', 'rowing', 'watching', 'pushing', 'blowing', 'phoning', 'looking', 'playing', 'walking', 'smoking', 'playing', 'jumping', 'waving', 'pouring', 'using', 'pushing', 'playing', 'phoning', 'running', 'jumping', 'using', 'writing', 'writing', 'pushing', 'applauding', 'washing', 'playing', 'playing', 'throwing', 'fixing', 'riding')\n"
     ]
    }
   ],
   "source": [
    "# Example to get one batch of data\n",
    "for images, labels in train_loader:\n",
    "    # Here images is a batch of images and labels is a batch of corresponding labels\n",
    "    print(images.shape, labels)\n",
    "    break  # Remove this break to iterate over the whole dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea8cf0df5bf15f1"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Define device for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "389df5ae80b2bb39"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnhancedCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=40, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EnhancedCNN(nn.Module):\n",
    "    # Improved CNN architecture with more layers and advanced techniques\n",
    "    def __init__(self, num_classes=40):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(128, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate and print the model architecture\n",
    "model = EnhancedCNN(num_classes=40).to(device)\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T17:19:34.462323Z",
     "start_time": "2024-01-08T17:19:34.457041Z"
    }
   },
   "id": "d7d64972339f5fe4"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.7034433517456056\n",
      "Validation Accuracy: 1.7534345625451917%\n",
      "Model improved and saved with 1.7534345625451917% accuracy\n",
      "Epoch 2, Loss: 3.7012274532318115\n",
      "Validation Accuracy: 1.7534345625451917%\n",
      "Epoch 3, Loss: 3.7010088024139405\n",
      "Validation Accuracy: 1.7534345625451917%\n",
      "Epoch 4, Loss: 3.7009871082305907\n",
      "Validation Accuracy: 1.7534345625451917%\n",
      "Epoch 5, Loss: 3.700985462188721\n",
      "Validation Accuracy: 1.7534345625451917%\n",
      "Epoch 6, Loss: 3.700985439300537\n",
      "Validation Accuracy: 1.7534345625451917%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 38>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     52\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m# Backward pass and optimize\u001B[39;00m\n\u001B[0;32m---> 55\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     58\u001B[0m \u001B[38;5;66;03m# Print statistics\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Move the model to the chosen device\n",
    "model.to(device)\n",
    "\n",
    "# Assuming labels are strings, we need to convert them to integers for training\n",
    "# Create a dictionary mapping each label to a unique integer\n",
    "unique_labels = sorted(set([label for _, label in train_dataset]))\n",
    "label_dict = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Optional: Define a learning rate scheduler\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "# Define the number of epochs for training\n",
    "num_epochs = 100\n",
    "\n",
    "# Function for validation phase\n",
    "def validate(model, val_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), [label_dict[label] for label in labels]\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return 100 * correct / total\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Convert labels to tensor indices\n",
    "        labels = torch.tensor([label_dict[label] for label in labels]).to(device)\n",
    "        \n",
    "        # Move the images to the device\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print epoch loss\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}, Loss: {epoch_loss}')\n",
    "    \n",
    "    # Validation phase\n",
    "    val_acc = validate(model, test_loader)\n",
    "    print(f'Validation Accuracy: {val_acc}%')\n",
    "\n",
    "    # Save the model if the accuracy is the best so far\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'Model improved and saved with {best_acc}% accuracy')\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:25:43.323100Z",
     "start_time": "2024-01-08T19:06:50.673100Z"
    }
   },
   "id": "e81f974afeadfcd2"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 91>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     97\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(images)\n\u001B[1;32m     98\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[0;32m---> 99\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    100\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    101\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "class Stanford40Dataset(Dataset):\n",
    "    def __init__(self, img_dir, split_file, transform=None, label_dict=None):\n",
    "        self.img_dir = img_dir\n",
    "        with open(split_file, 'r') as file:\n",
    "            self.img_list = file.readlines()\n",
    "        self.transform = transform\n",
    "        self.label_dict = label_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx].rstrip('\\n')\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.label_dict[img_name.split('_')[0]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "transform = Compose([Resize((256, 256)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "img_dir = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/JPEGImages'\n",
    "train_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/train.txt'\n",
    "test_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/test.txt'\n",
    "unique_labels = sorted(set([line.split('_')[0] for line in open(train_split_file, 'r')]))\n",
    "label_dict = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "train_dataset = Stanford40Dataset(img_dir, train_split_file, transform=transform, label_dict=label_dict)\n",
    "test_dataset = Stanford40Dataset(img_dir, test_split_file, transform=transform, label_dict=label_dict)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=40):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(128, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.75)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = EnhancedCNN(num_classes=40).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "# Place the validate function here\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "num_epochs = 200\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "\n",
    "    val_acc = validate(model, test_loader)\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "print('Finished Training')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:05:11.569335Z",
     "start_time": "2024-01-09T09:33:49.369298Z"
    }
   },
   "id": "87fb31c40e2a50ec"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 7.393347794649313%\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the test images: {100 * correct / total}%')\n",
    "\n",
    "# Call the test_model function\n",
    "test_model(model, test_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T09:32:56.049505Z",
     "start_time": "2024-01-09T09:31:53.655056Z"
    }
   },
   "id": "ec1e4898322baaf2"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy: 11.171366594360087%\n",
      "Epoch 2: Validation Accuracy: 11.478669558929862%\n",
      "Epoch 3: Validation Accuracy: 12.79826464208243%\n",
      "Epoch 4: Validation Accuracy: 13.322487346348518%\n",
      "Epoch 5: Validation Accuracy: 13.376717281272596%\n",
      "Test Accuracy: 13.250180766449747%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Dataset class for Stanford 40\n",
    "class Stanford40Dataset(Dataset):\n",
    "    def __init__(self, img_dir, split_file, transform=None, label_dict=None):\n",
    "        self.img_dir = img_dir\n",
    "        with open(split_file, 'r') as file:\n",
    "            self.img_list = file.readlines()\n",
    "        self.transform = transform\n",
    "        self.label_dict = label_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx].rstrip('\\n')\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.label_dict[img_name.split('_')[0]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "# Enhanced Transform with Augmentations\n",
    "transform = Compose([\n",
    "    Resize((256, 256)), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Paths and dataset loaders\n",
    "img_dir = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/JPEGImages'\n",
    "train_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/train.txt'\n",
    "test_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/test.txt'\n",
    "unique_labels = sorted(set([line.split('_')[0] for line in open(train_split_file, 'r')]))\n",
    "label_dict = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "train_dataset = Stanford40Dataset(img_dir, train_split_file, transform=transform, label_dict=label_dict)\n",
    "test_dataset = Stanford40Dataset(img_dir, test_split_file, transform=transform, label_dict=label_dict)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=40, activation='tanh'):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        # Define layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(128, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Activation function selection\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activation(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.activation(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.activation(self.bn3(self.conv3(x))))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Validation function\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model and move it to the device\n",
    "model = EnhancedCNN(num_classes=40, activation='tanh').to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer with the learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.05)\n",
    "\n",
    "# Specify the number of epochs \n",
    "num_epochs = 5  \n",
    "\n",
    "# Initialize the best validation accuracy variable\n",
    "best_acc = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over the training set\n",
    "    for images, labels in train_loader:\n",
    "        # Transfer images and labels to your device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Adjust the learning rate based on the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Validation step after each epoch\n",
    "    val_acc = validate(model, test_loader)\n",
    "    print(f'Epoch {epoch+1}: Validation Accuracy: {val_acc}%')\n",
    "    \n",
    "    # Check if the validation accuracy is the best and save the model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Test function\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Test the model after training\n",
    "test_accuracy = test_model(model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy}%')\n",
    "\n",
    "# Save test results to a file\n",
    "with open('test_accuracy.txt', 'w') as file:\n",
    "    file.write(f'Test Accuracy: {test_accuracy}%\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T21:54:54.308774Z",
     "start_time": "2024-01-09T21:34:42.363838Z"
    }
   },
   "id": "48f15ce094b0e69c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Training Loss: 2.4899, Validation Loss: 2.3571, Validation Accuracy: 36.01%\n",
      "Epoch 2/5, Training Loss: 1.8237, Validation Loss: 2.5072, Validation Accuracy: 37.85%\n",
      "Epoch 3/5, Training Loss: 1.4577, Validation Loss: 2.0845, Validation Accuracy: 44.96%\n",
      "Epoch 4/5, Training Loss: 1.2442, Validation Loss: 2.3500, Validation Accuracy: 41.09%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "# Dataset class for Stanford 40\n",
    "class Stanford40Dataset(Dataset):\n",
    "    def __init__(self, img_dir, split_file, transform=None, label_dict=None):\n",
    "        self.img_dir = img_dir\n",
    "        with open(split_file, 'r') as file:\n",
    "            self.img_list = file.readlines()\n",
    "        self.transform = transform\n",
    "        self.label_dict = label_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx].rstrip('\\n')\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.label_dict[img_name.split('_')[0]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "# Enhanced Transform with Augmentations\n",
    "transform = Compose([\n",
    "    Resize((256, 256)), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Paths and dataset loaders\n",
    "img_dir = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/JPEGImages'\n",
    "train_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/train.txt'\n",
    "test_split_file = '/Users/mwr/Downloads/AVPR assignment 2/Stanford40/ImageSplits/test.txt'\n",
    "unique_labels = sorted(set([line.split('_')[0] for line in open(train_split_file, 'r')]))\n",
    "label_dict = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "\n",
    "train_dataset = Stanford40Dataset(img_dir, train_split_file, transform=transform, label_dict=label_dict)\n",
    "test_dataset = Stanford40Dataset(img_dir, test_split_file, transform=transform, label_dict=label_dict)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "resnet_model = models.resnet18(pretrained=True)\n",
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, 40)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(resnet_model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return val_loss / len(val_loader), 100 * correct / total\n",
    "\n",
    "\n",
    "best_model_wts = copy.deepcopy(resnet_model.state_dict())\n",
    "best_acc = 0.0\n",
    "early_stopping_patience = 5\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "num_epochs = 5  # Set  number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    resnet_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    val_loss, val_acc = validate(resnet_model, test_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%')\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(resnet_model.state_dict())\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "        if no_improvement_epochs >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "resnet_model.load_state_dict(best_model_wts)\n",
    "\n",
    "\n",
    "# Test function\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "test_accuracy = test_model(resnet_model, test_loader)\n",
    "with open('resnet_test_results.txt', 'w') as file:\n",
    "    file.write(f'Test Accuracy: {test_accuracy}%\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-09T22:17:40.612931Z"
    }
   },
   "id": "80c2bea3b4d468f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "31bb664dbda0499d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
